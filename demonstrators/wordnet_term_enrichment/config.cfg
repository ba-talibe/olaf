[data_preprocessing]
base_pipeline = null
tokenizer = null
extra_components = null

[data_preprocessing.corpus]
# if `corpus_path` is not an absolute path, the relative path is expected to be given from the `data/` forder.
corpus_path =  null
json_field = null
csv_separator = null

[data_preprocessing.token_selector]
pipeline_name = null
token_selector_names = null
doc_attribute_name = null
make_spans = null

[data_preprocessing.token_selector.select_on_shape_match_pattern]
shape_pattern_to_select = null

[term_extraction]
selected_tokens_doc_attribute = ${data_preprocessing.token_selector.doc_attribute_name}

[term_extraction.c_value]
max_size_gram = null
treshold = null

[term_extraction.on_pos]
pos_selection = null
use_lemma = null

[term_extraction.on_occurence]
occurence_threshold = null
use_lemma = null

[term_enrichment]
candidate_terms_path = null

[term_enrichment.wordnet]
wordnet_domain_path = "demo_data/wordnet_domains.txt"
lang = "en"
use_domains = true
use_pos = true
enrichment_domains = null
enrichment_domains_file = "demo_data/wn_enrichment_domains.txt"
synset_pos = ["NOUN"]