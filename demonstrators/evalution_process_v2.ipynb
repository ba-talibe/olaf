{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we aim to develop a protocole to evaluate OLAF pipelines:\n",
    "\n",
    "\n",
    "To achieve this task , we will follow this steps:\n",
    "\n",
    "- Select a corpus.\n",
    "- Select and create relevent concepts from the corpus.\n",
    "- Create several pipelines with different components and parameters.\n",
    "- Run all the pipelines.\n",
    "- Find concepts involved in complete triples (relation with no null source and destination concepts) for each pipeline.\n",
    "- Etablish the matching percentage of found concepts compared to selected concepts on step 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Set, List\n",
    "\n",
    "from olaf import Pipeline\n",
    "from olaf.data_container.relation_schema import Relation, Concept\n",
    "from olaf.data_container.knowledge_representation_schema import KnowledgeRepresentation\n",
    "from olaf.pipeline.pipeline_component.term_extraction import POSTermExtraction\n",
    "from olaf.pipeline.pipeline_component.concept_relation_extraction import (\n",
    "    CTsToConceptExtraction,\n",
    "    CTsToRelationExtraction,\n",
    "    SynonymRelationExtraction,\n",
    "    SynonymConceptExtraction,\n",
    "    AgglomerativeClusteringRelationExtraction,\n",
    "    AgglomerativeClusteringConceptExtraction\n",
    ")\n",
    "from olaf.pipeline.pipeline_component.term_extraction.tfidf_term_extraction import (\n",
    "    TFIDFTermExtraction,\n",
    ")\n",
    "from olaf.pipeline.pipeline_component.term_extraction.manual_candidate_terms import (\n",
    "    ManualCandidateTermExtraction,\n",
    ")\n",
    "from olaf.repository.corpus_loader.text_corpus_loader import TextCorpusLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Each defect type is described in detail, explaining how it appears on the steel strip surface and the reasons behind its occurrence:',\n",
       " '    Punching: In the production line of the strip, the steel strip needs to be punched according to the product specifications; mechanical failure may lead to unwanted punching, resulting in punching defects.',\n",
       " '    Welding line: When the strip is changed, it is necessary to weld the two coils of the strip, and the weld line is produced. Strictly speaking, this is not a defect, but it needs to be automatically detected and tracked to be circumvented in subsequent cuts.',\n",
       " '    Crescent gap: In the production of steel strip, cutting sometimes results in defects, just like half a circle.',\n",
       " '    Water spot: A water spot is produced by drying in production. Under different products and processes, the requirements for this defect are different. However, because the water spots are generally with low contrast, and are similar to other defects such as oil spots, they are usually detected by mistake.',\n",
       " '    Oil spot: An oil spot is usually caused by the contamination of mechanical lubricant, which will affect the appearance of the product.',\n",
       " '    Silk spot: A local or continuous wave-like plaque on a strip surface that may appear on the upper and lower surfaces, and the density is uneven in the whole strip length direction. Generally, the main reason lies in the uneven temperature of the roller and uneven pressure.',\n",
       " '    Inclusion: Inclusion is a typical defect of metal surface defects, usually showing small spots, fish scale shape, strip shape, block irregular distribution in the strip of the upper and lower surface (global or local), and is often accompanied by rough pockmarked surfaces. Some inclusions are loose and easy to fall off and some are pressed into the plate.',\n",
       " '    Rolled pit: Rolled pits are periodic bulges or pits on the surface of a steel plate that are punctate, flaky, or strip-like. They are distributed throughout the strip length or section, mainly caused by work roll or tension roll damage.',\n",
       " '    Crease: A crease is a vertical transverse fold, with regular or irregular spacing across the strip, or at the edge of the strip. The main reason is the local yield along the moving direction of the strip in the uncoiling process.',\n",
       " '    Waist folding: There are obvious folds in the defect parts, a little more popular, a little like wrinkles, indicating that the local deformation of the defect is too large. The reason is due to low-carbon.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = \"GC10-DET_doc.txt\"\n",
    "corpus = TextCorpusLoader(corpus_path)._read_corpus()\n",
    "corpus = [doc[:-1] for doc in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and create relevent concepts from the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knfjre'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"knfjre\\n\".rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Punching, Welding line, Crescent Gap, Water spot, Oil spot, Silk spot, Inclusion, Rolled pit, Crease, Waist folding, metal surface defect, mechanical failure, drying, mechanical lubricant, temperature, pressure, work roll damage, tension roll damage, local yield, low-carbon]\n"
     ]
    }
   ],
   "source": [
    "expected_concepts = []\n",
    "with open(\"concepts.txt\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    expected_concepts = [concept.rstrip(\"\\n\") for concept in lines]\n",
    "    expected_concepts = [Concept(concept) for concept in expected_concepts]\n",
    "    f.close()\n",
    "\n",
    "print(expected_concepts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing concept ratio function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "def is_similar(concept_a : str, concept_b: str, nlp =nlp, threshold=.8):\n",
    "    vector_a, vector_b = nlp(concept_a).vector, nlp(concept_b).vector\n",
    "    return cosine_similarity([vector_a], [vector_b]) > threshold\n",
    "\n",
    "def is_equal(concept_a : str, concept_b: str):\n",
    "    return concept_a.lower() == concept_b.lower()\n",
    "\n",
    "def hg_lm_similaritiry(concept_a : str, concept_b: str, model=SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"), threshold=.8):\n",
    "    embedding_a, embedding_b = model.encode(concept_a), model.encode(concept_b)\n",
    "    return util.pytorch_cos_sim(embedding_a, embedding_b) > threshold\n",
    "\n",
    "def get_concept_ratio(pipeline : Pipeline, expected_concepts : List[Concept], comparator = hg_lm_similaritiry, comparator_args:dict={}) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the ratio of expected and unexpected concepts in a given pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline : Pipeline\n",
    "        The pipeline object containing concepts.\n",
    "    expected_concepts : List[Concept]\n",
    "        A list of expected concepts.kwargs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]: A tuple containing:\n",
    "        The percentage of expected concepts found in the pipeline.\n",
    "        The percentage of unexpected concepts in the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    found_concepts = pipeline.kr.concepts\n",
    "    found_concepts = [found_concept.label for found_concept in found_concepts]\n",
    "    expected_concepts = [expected_concept.label for expected_concept in expected_concepts]\n",
    "    expected_concept_occ = 0\n",
    "    for expected_concept in expected_concepts:\n",
    "        for found_concept in found_concepts:\n",
    "            if comparator(expected_concept, found_concept, **comparator_args):\n",
    "                expected_concept_occ += 1\n",
    "                break \n",
    "\n",
    "  \n",
    "    precision = expected_concept_occ/len(expected_concepts)\n",
    "    recall = expected_concept_occ/len(found_concepts)\n",
    "    f1 = 2*(precision * recall)/(precision+recall)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 15:41:49,263] [WARNING] [candidate_terms_to_relations] [_check_parameters] [No value given for concept_max_distance parameter, default will be set to 5.]\n"
     ]
    }
   ],
   "source": [
    "from olaf.pipeline.pipeline_component.term_extraction.manual_candidate_terms import (\n",
    "    ManualCandidateTermExtraction,\n",
    ")\n",
    "from olaf.pipeline.pipeline_component.concept_relation_extraction.candidate_terms_to_concepts import CTsToConceptExtraction\n",
    "\n",
    "from olaf.pipeline.pipeline_component.concept_relation_extraction.candidate_terms_to_relations import CTsToRelationExtraction\n",
    "\n",
    "\n",
    "# concept extraction component\n",
    "concepts = [\n",
    "    \"defect type\",\n",
    "    \"steel strip surface\",\n",
    "    \"punching\",\n",
    "    \"mechanical failure\",\n",
    "    \"welding line\",\n",
    "    \"coil\",\n",
    "    \"weld line\",\n",
    "    \"crescent gap\",\n",
    "    \"cutting\",\n",
    "    \"water spot\",\n",
    "    \"drying\",\n",
    "    \"oil spot\",\n",
    "    \"mechanical lubricant\",\n",
    "    \"silk spot\",\n",
    "    \"plaque\",\n",
    "    \"strip surface\",\n",
    "    \"roller\",\n",
    "    \"pressure\",\n",
    "    \"inclusion\",\n",
    "    \"metal surface\",\n",
    "    \"spots\",\n",
    "    \"fish scale shape\",\n",
    "    \"block irregular distribution\",\n",
    "    \"rolled pit\",\n",
    "    \"bulges\",\n",
    "    \"pits\",\n",
    "    \"steel plate\",\n",
    "    \"work roll\",\n",
    "    \"tension roll\",\n",
    "    \"damage\",\n",
    "    \"crease\",\n",
    "    \"fold\",\n",
    "    \"uncoiling process\",\n",
    "    \"waist folding\",\n",
    "    \"deformation\",\n",
    "    \"low-carbon\"\n",
    "]\n",
    "\n",
    "relations = [\n",
    "    \"described\",\n",
    "    \"explaining\",\n",
    "    \"appears\",\n",
    "    \"leads\",\n",
    "    \"resulting\",\n",
    "    \"changed\",\n",
    "    \"produced\",\n",
    "    \"drying\",\n",
    "    \"caused\",\n",
    "    \"affect\",\n",
    "    \"appearing\",\n",
    "    \"lies\",\n",
    "    \"distributed\",\n",
    "    \"accompanied\",\n",
    "    \"showing\",\n",
    "    \"pressed\",\n",
    "    \"occurred\",\n",
    "    \"circumvented\",\n",
    "    \"detected\",\n",
    "    \"tracked\",\n",
    "    \"results\",\n",
    "    \"like\",\n",
    "    \"mainly\",\n",
    "    \"uncoiling\"\n",
    "]\n",
    "\n",
    "ct_concept_label = { concept : {concept} for concept in concepts}\n",
    "\n",
    "manuel_concept_extraction = ManualCandidateTermExtraction(\n",
    "    ct_label_strings_map=ct_concept_label\n",
    ")\n",
    "\n",
    "concept_extraction = CTsToConceptExtraction(\n",
    ")\n",
    "# concept extraction component\n",
    "\n",
    "\n",
    "\n",
    "relation_extraction = CTsToRelationExtraction()\n",
    "pipelines = []\n",
    "pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            manuel_concept_extraction,\n",
    "            concept_extraction,\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.45714285714285713, 0.5818181818181818)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pipeline = pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching \n",
      "Welding line : weld line \n",
      "Crescent Gap : crescent gap \n",
      "Water spot : water spot \n",
      "Oil spot : oil spot \n",
      "Silk spot : silk spot \n",
      "Inclusion : inclusion \n",
      "Rolled pit : rolled pit \n",
      "Crease : crease \n",
      "Waist folding : waist folding \n",
      "metal surface defect : \n",
      "mechanical failure : mechanical failure \n",
      "drying : drying \n",
      "mechanical lubricant : mechanical lubricant \n",
      "temperature : \n",
      "pressure : pressure \n",
      "work roll damage : \n",
      "tension roll damage : tension roll \n",
      "local yield : \n",
      "low-carbon : low-carbon "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 0.45714285714285713, 0.5818181818181818)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug_get_concept_ratio(pipeline : Pipeline, expected_concepts : List[Concept], comparator = hg_lm_similaritiry, comparator_args:dict={}) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the ratio of expected and unexpected concepts in a given pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline : Pipeline\n",
    "        The pipeline object containing concepts.\n",
    "    expected_concepts : List[Concept]\n",
    "        A list of expected concepts.kwargs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]: A tuple containing:\n",
    "        The percentage of expected concepts found in the pipeline.\n",
    "        The percentage of unexpected concepts in the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    found_concepts = pipeline.kr.concepts\n",
    "    found_concepts = [found_concept.label for found_concept in found_concepts]\n",
    "    expected_concepts = [expected_concept.label for expected_concept in expected_concepts]\n",
    "    expected_concept_occ = 0\n",
    "    for expected_concept in expected_concepts:\n",
    "        print()\n",
    "        print(f\"{expected_concept} : \", end=\"\")\n",
    "        for found_concept in found_concepts:\n",
    "            if comparator(expected_concept, found_concept, **comparator_args):\n",
    "                print(f\"{found_concept} \", end=\"\")\n",
    "                expected_concept_occ += 1\n",
    "                break \n",
    "\n",
    "  \n",
    "    precision = expected_concept_occ/len(expected_concepts)\n",
    "    recall = expected_concept_occ/len(found_concepts)\n",
    "    f1 = 2*(precision * recall)/(precision+recall)\n",
    "    return (precision, recall, f1)\n",
    "\n",
    "\n",
    "\n",
    "current_pipeline = pipelines[-1]\n",
    "debug_get_concept_ratio(current_pipeline, expected_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching \n",
      "Welding line : weld line \n",
      "Crescent Gap : crescent gap \n",
      "Water spot : water spot \n",
      "Oil spot : oil spot \n",
      "Silk spot : silk spot \n",
      "Inclusion : inclusion \n",
      "Rolled pit : rolled pit \n",
      "Crease : crease \n",
      "Waist folding : waist folding \n",
      "metal surface defect : metal surface \n",
      "mechanical failure : mechanical failure \n",
      "drying : drying \n",
      "mechanical lubricant : mechanical lubricant \n",
      "temperature : \n",
      "pressure : pressure \n",
      "work roll damage : work roll \n",
      "tension roll damage : tension roll \n",
      "local yield : \n",
      "low-carbon : low-carbon "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9, 0.5142857142857142, 0.6545454545454545)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_get_concept_ratio(current_pipeline, expected_concepts, comparator_args={\"threshold\":.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching \n",
      "Welding line : welding line \n",
      "Crescent Gap : crescent gap \n",
      "Water spot : water spot \n",
      "Oil spot : oil spot \n",
      "Silk spot : silk spot \n",
      "Inclusion : inclusion \n",
      "Rolled pit : rolled pit \n",
      "Crease : crease \n",
      "Waist folding : waist folding \n",
      "metal surface defect : \n",
      "mechanical failure : mechanical failure \n",
      "drying : drying \n",
      "mechanical lubricant : mechanical lubricant \n",
      "temperature : \n",
      "pressure : pressure \n",
      "work roll damage : \n",
      "tension roll damage : \n",
      "local yield : \n",
      "low-carbon : low-carbon "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.75, 0.42857142857142855, 0.5454545454545454)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_get_concept_ratio(current_pipeline, expected_concepts, comparator=is_equal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching \n",
      "Welding line : weld line \n",
      "Crescent Gap : crescent gap \n",
      "Water spot : oil spot \n",
      "Oil spot : oil spot \n",
      "Silk spot : oil spot \n",
      "Inclusion : inclusion \n",
      "Rolled pit : rolled pit \n",
      "Crease : crease \n",
      "Waist folding : waist folding \n",
      "metal surface defect : steel strip surface \n",
      "mechanical failure : mechanical failure \n",
      "drying : drying \n",
      "mechanical lubricant : mechanical lubricant \n",
      "temperature : \n",
      "pressure : pressure \n",
      "work roll damage : damage \n",
      "tension roll damage : tension roll \n",
      "local yield : \n",
      "low-carbon : low-carbon "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9, 0.5142857142857142, 0.6545454545454545)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_get_concept_ratio(current_pipeline, expected_concepts, comparator_args={\"threshold\":.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimze the similarity threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8, 0.45714285714285713, 0.5818181818181818)\n",
      "(0.9, 0.5142857142857142, 0.6545454545454545)\n",
      "(0.9, 0.5142857142857142, 0.6545454545454545)\n",
      "(0.9, 0.5142857142857142, 0.6545454545454545)\n"
     ]
    }
   ],
   "source": [
    "print(get_concept_ratio(current_pipeline, expected_concepts)) # default threshold is 0.8\n",
    "print(get_concept_ratio(current_pipeline, expected_concepts, comparator_args={\"threshold\": 0.7}))\n",
    "print(get_concept_ratio(current_pipeline, expected_concepts, comparator_args={\"threshold\": 0.6}))\n",
    "print(get_concept_ratio(current_pipeline, expected_concepts, comparator_args={\"threshold\": 0.5}))\n",
    "\n",
    "comparator_args={\"threshold\": 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  a grid search algorithm for pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "    def __init__(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_concept(kr: KnowledgeRepresentation) -> None:\n",
    "    print(\"Concepts in KR:\")\n",
    "    for concept in kr.concepts:\n",
    "        print(concept.label)\n",
    "\n",
    "\n",
    "def display_relation(kr: KnowledgeRepresentation) -> None:\n",
    "    print(\"Relations in KR:\")\n",
    "    for relation in kr.relations:\n",
    "        if (\n",
    "            relation.source_concept is not None\n",
    "            or relation.destination_concept is not None\n",
    "        ):\n",
    "            print(\n",
    "                (\n",
    "                    relation.source_concept.label,\n",
    "                    relation.label,\n",
    "                    relation.destination_concept.label,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olaf.pipeline.pipeline_component.term_extraction import (\n",
    "    ManualCandidateTermExtraction,\n",
    "    POSTermExtraction,\n",
    "    TFIDFTermExtraction,\n",
    "    CvalueTermExtraction\n",
    ")\n",
    "\n",
    "from olaf.pipeline.pipeline_component.concept_relation_extraction import (\n",
    "    CTsToConceptExtraction,\n",
    "    SynonymConceptExtraction,\n",
    "    AgglomerativeClusteringConceptExtraction\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuelle Term  Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_pipelines = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelle Term  Extraction and Candidat To Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 0.5142857142857142, 0.6545454545454545)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concept extraction component\n",
    "concepts = [\n",
    "    \"defect type\",\n",
    "    \"steel strip surface\",\n",
    "    \"punching\",\n",
    "    \"mechanical failure\",\n",
    "    \"welding line\",\n",
    "    \"coil\",\n",
    "    \"weld line\",\n",
    "    \"crescent gap\",\n",
    "    \"cutting\",\n",
    "    \"water spot\",\n",
    "    \"drying\",\n",
    "    \"oil spot\",\n",
    "    \"mechanical lubricant\",\n",
    "    \"silk spot\",\n",
    "    \"plaque\",\n",
    "    \"strip surface\",\n",
    "    \"roller\",\n",
    "    \"pressure\",\n",
    "    \"inclusion\",\n",
    "    \"metal surface\",\n",
    "    \"spots\",\n",
    "    \"fish scale shape\",\n",
    "    \"block irregular distribution\",\n",
    "    \"rolled pit\",\n",
    "    \"bulges\",\n",
    "    \"pits\",\n",
    "    \"steel plate\",\n",
    "    \"work roll\",\n",
    "    \"tension roll\",\n",
    "    \"damage\",\n",
    "    \"crease\",\n",
    "    \"fold\",\n",
    "    \"uncoiling process\",\n",
    "    \"waist folding\",\n",
    "    \"deformation\",\n",
    "    \"low-carbon\"\n",
    "]\n",
    "\n",
    "ct_concept_label = { concept : {concept} for concept in concepts}\n",
    "\n",
    "\n",
    "manual_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            ManualCandidateTermExtraction(\n",
    "                ct_label_strings_map=ct_concept_label\n",
    "            ),\n",
    "            CTsToConceptExtraction(),\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = manual_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelle Term  Extraction and Synonym Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 0.5142857142857142, 0.6545454545454545)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "manual_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            ManualCandidateTermExtraction(\n",
    "                ct_label_strings_map=ct_concept_label\n",
    "            ),\n",
    "            SynonymConceptExtraction(),\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = manual_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelle Term  Extraction and Agglomerative Clustering Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 17:31:18,867] [WARNING] [agglomerative_clustering_concept_extraction] [_check_parameters] [No value given for embedding_model parameter, default will be set to all-mpnet-base-v2.]\n",
      "[2024-06-14 17:31:18,868] [WARNING] [agglomerative_clustering_concept_extraction] [_check_parameters] [No value given for metric option, default will be set to cosine.]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 1.96 GiB of which 65.88 MiB is free. Including non-PyTorch memory, this process has 1.31 GiB memory in use. Of the allocated memory 1.19 GiB is allocated by PyTorch, and 84.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m manual_pipelines\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m      2\u001b[0m     Pipeline(\n\u001b[1;32m      3\u001b[0m         spacy_model\u001b[38;5;241m=\u001b[39mnlp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m current_pipeline \u001b[38;5;241m=\u001b[39m manual_pipelines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m \u001b[43mcurrent_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/olaf/pipeline/pipeline_schema.py:147\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m     component\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_components:\n\u001b[0;32m--> 147\u001b[0m     \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/olaf/pipeline/pipeline_component/concept_relation_extraction/agglomerative_clustering_concept_extraction.py:184\u001b[0m, in \u001b[0;36mAgglomerativeClusteringConceptExtraction.run\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(pipeline\u001b[38;5;241m.\u001b[39mcandidate_terms)\n\u001b[0;32m--> 184\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43msbert_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidate_terms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     agglo_clustering \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(\n\u001b[1;32m    189\u001b[0m         embeddings,\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nb_clusters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance_threshold,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     agglo_clustering\u001b[38;5;241m.\u001b[39mcompute_agglomerative_clustering()\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/olaf/commons/embedding_tools.py:6\u001b[0m, in \u001b[0;36msbert_embeddings\u001b[0;34m(model_name, words)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msbert_embeddings\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, words: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any : \n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(words)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:316\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    312\u001b[0m     modules \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(modules)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Bureau/ontology-learning/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 1.96 GiB of which 65.88 MiB is free. Including non-PyTorch memory, this process has 1.31 GiB memory in use. Of the allocated memory 1.19 GiB is allocated by PyTorch, and 84.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "manual_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            ManualCandidateTermExtraction(\n",
    "                ct_label_strings_map=ct_concept_label\n",
    "            ),\n",
    "            AgglomerativeClusteringConceptExtraction(\n",
    "                distance_threshold=.3\n",
    "            ),\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = manual_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "# get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tag Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "postag_pipelines = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tag Term  extraction and Candidat To Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 17:13:50,508] [WARNING] [pos_term_extraction] [__init__] [No preprocessing function provided for spans. Using the default one.]\n",
      "[2024-06-14 17:13:50,509] [WARNING] [pos_term_extraction] [_check_parameters] [POS term extraction token sequence attribute not set by the user.\n",
      "               By default the system will use the entire content of the document.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1643835616438356, 0.25806451612903225)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            POSTermExtraction(\n",
    "                pos_selection=[\"NOUN\"]\n",
    "            ),\n",
    "            CTsToConceptExtraction()\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = postag_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching \n",
      "Welding line : \n",
      "Crescent Gap : gap \n",
      "Water spot : \n",
      "Oil spot : \n",
      "Silk spot : silk \n",
      "Inclusion : inclusions \n",
      "Rolled pit : pit \n",
      "Crease : crease \n",
      "Waist folding : fold \n",
      "metal surface defect : \n",
      "mechanical failure : \n",
      "drying : \n",
      "mechanical lubricant : lubricant \n",
      "temperature : temperature \n",
      "pressure : pressure \n",
      "work roll damage : \n",
      "tension roll damage : \n",
      "local yield : yield \n",
      "low-carbon : carbon "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1643835616438356, 0.25806451612903225)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tag Term  extraction and Synonym Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 17:17:15,197] [WARNING] [pos_term_extraction] [__init__] [No preprocessing function provided for spans. Using the default one.]\n",
      "[2024-06-14 17:17:15,199] [WARNING] [pos_term_extraction] [_check_parameters] [POS term extraction token sequence attribute not set by the user.\n",
      "               By default the system will use the entire content of the document.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1643835616438356, 0.25806451612903225)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            POSTermExtraction(\n",
    "                pos_selection=[\"NOUN\"]\n",
    "            ),\n",
    "            SynonymConceptExtraction()\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = postag_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tag Term  extraction and Agglomerative clustering Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 17:17:31,199] [WARNING] [pos_term_extraction] [__init__] [No preprocessing function provided for spans. Using the default one.]\n",
      "[2024-06-14 17:17:31,200] [WARNING] [pos_term_extraction] [_check_parameters] [POS term extraction token sequence attribute not set by the user.\n",
      "               By default the system will use the entire content of the document.]\n",
      "[2024-06-14 17:17:31,202] [WARNING] [agglomerative_clustering_concept_extraction] [_check_parameters] [No value given for embedding_model parameter, default will be set to all-mpnet-base-v2.]\n",
      "[2024-06-14 17:17:31,203] [WARNING] [agglomerative_clustering_concept_extraction] [_check_parameters] [No value given for metric option, default will be set to cosine.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1643835616438356, 0.25806451612903225)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            POSTermExtraction(\n",
    "                pos_selection=[\"NOUN\"]\n",
    "            ),\n",
    "            AgglomerativeClusteringConceptExtraction(\n",
    "                distance_threshold=.3\n",
    "            )\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF  Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipelines = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Term Extraction and Candidat To Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 17:22:14,528] [WARNING] [tfidf_term_extraction] [_check_parameters] [Selected token sequence document attribute not set by the user.\n",
      "                By default the system will use the entire content of the document.]\n",
      "/home/oumar/Bureau/ontology-learning/env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4, 0.034334763948497854, 0.06324110671936758)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            TFIDFTermExtraction(\n",
    "                max_term_token_length=3,\n",
    "                candidate_term_threshold=.1\n",
    "            ),\n",
    "            CTsToConceptExtraction()\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = tfidf_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punching : punching : in \n",
      "Welding line : \n",
      "Crescent Gap : crescent gap : \n",
      "Water spot : water spot \n",
      "Oil spot : oil spot : \n",
      "Silk spot : \n",
      "Inclusion : inclusion \n",
      "Rolled pit : \n",
      "Crease : crease \n",
      "Waist folding : \n",
      "metal surface defect : \n",
      "mechanical failure : mechanical failure may \n",
      "drying : \n",
      "mechanical lubricant : of mechanical lubricant \n",
      "temperature : \n",
      "pressure : \n",
      "work roll damage : \n",
      "tension roll damage : \n",
      "local yield : \n",
      "low-carbon : "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4, 0.034334763948497854, 0.06324110671936758)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts in KR:\n",
      "appears on the\n",
      "affect\n",
      "punching : in\n",
      "strip , the\n",
      "in defects ,\n",
      "roll\n",
      "described in detail\n",
      "strip surface and\n",
      "detail ,\n",
      "punched according to\n",
      "and\n",
      "type\n",
      "defects .\n",
      "appearance\n",
      "crease\n",
      "a circle\n",
      "half\n",
      "defects , just\n",
      "in detail ,\n",
      "according to the\n",
      "the appearance\n",
      ", explaining\n",
      "of mechanical lubricant\n",
      "described\n",
      "in punching defects\n",
      "surface and the\n",
      ";\n",
      "the production line\n",
      ", just like\n",
      "failure may\n",
      "circle\n",
      ": an\n",
      "product specifications ;\n",
      "circle .\n",
      "or\n",
      "detail , explaining\n",
      "punched\n",
      "and the reasons\n",
      "little\n",
      "mechanical lubricant ,\n",
      "detail\n",
      "the steel\n",
      "appearance of\n",
      "an oil\n",
      "explaining how\n",
      ", resulting in\n",
      ": in\n",
      "to unwanted\n",
      "failure may lead\n",
      "to unwanted punching\n",
      "the defect\n",
      "crescent gap :\n",
      "just like half\n",
      ", the steel\n",
      "crescent gap\n",
      "in punching\n",
      "unwanted punching ,\n",
      "lubricant , which\n",
      "explaining\n",
      ", explaining how\n",
      "product .\n",
      "the reasons behind\n",
      "to the product\n",
      "be punched according\n",
      "contamination\n",
      "like half a\n",
      "explaining how it\n",
      "gap :\n",
      "is usually\n",
      "how it\n",
      "gap : in\n",
      "how\n",
      "how it appears\n",
      "oil spot :\n",
      "line of\n",
      "may lead to\n",
      ", which will\n",
      "half a circle\n",
      "it appears on\n",
      "production of\n",
      "resulting in\n",
      "reasons behind its\n",
      ", a\n",
      "punching , resulting\n",
      "appears\n",
      "punching defects .\n",
      "usually caused\n",
      "it appears\n",
      "the production of\n",
      "punching ,\n",
      "spot : an\n",
      "the\n",
      "a little\n",
      "which will affect\n",
      "a circle .\n",
      "of steel\n",
      "behind its occurrence\n",
      "appears on\n",
      "production of steel\n",
      "reasons\n",
      ": an oil\n",
      "by the\n",
      "be punched\n",
      "will affect the\n",
      "to be punched\n",
      ", cutting\n",
      "to the\n",
      ", a little\n",
      ": in the\n",
      "steel strip needs\n",
      "an oil spot\n",
      "its occurrence :\n",
      "surface and\n",
      "of steel strip\n",
      "inclusion\n",
      "cutting sometimes\n",
      "the contamination\n",
      "the product specifications\n",
      "affect the appearance\n",
      "behind\n",
      "oil spot is\n",
      "the production\n",
      "water\n",
      "unwanted punching\n",
      "shape\n",
      "sometimes results\n",
      "are\n",
      "the reasons\n",
      ", resulting\n",
      "its\n",
      "spot is usually\n",
      "contamination of\n",
      "lubricant\n",
      "steel strip ,\n",
      "some\n",
      "to be\n",
      "line of the\n",
      "oil spot\n",
      "the appearance of\n",
      "occurrence\n",
      "results in\n",
      "oil\n",
      "strip , cutting\n",
      "reasons behind\n",
      "production line\n",
      "is usually caused\n",
      "of mechanical\n",
      "appearance of the\n",
      "in the production\n",
      "specifications\n",
      "spot\n",
      "crescent\n",
      "strip needs\n",
      "uneven\n",
      "shape ,\n",
      "in defects\n",
      "mechanical lubricant\n",
      "an\n",
      "behind its\n",
      "each defect\n",
      "usually caused by\n",
      "specifications ; mechanical\n",
      ", cutting sometimes\n",
      "mechanical failure may\n",
      "production line of\n",
      "punched according\n",
      "gap\n",
      "of the product\n",
      "punching\n",
      "different\n",
      ", just\n",
      "resulting in punching\n",
      "product specifications\n",
      "its occurrence\n",
      "defect type\n",
      "caused by the\n",
      "lubricant ,\n",
      "specifications ;\n",
      "be\n",
      "water spot\n",
      "mechanical failure\n",
      "cutting\n",
      "cutting sometimes results\n",
      "occurrence :\n",
      "type is\n",
      "punching defects\n",
      ", which\n",
      "the product .\n",
      "according to\n",
      "unwanted\n",
      "just like\n",
      "sometimes\n",
      "lead to unwanted\n",
      "lead to\n",
      "weld\n",
      "by the contamination\n",
      "; mechanical failure\n",
      "sometimes results in\n",
      "each defect type\n",
      "is described\n",
      "which\n",
      "punching :\n",
      "which will\n",
      "the steel strip\n",
      "failure\n",
      "on the steel\n",
      "rolled\n",
      "; mechanical\n",
      "lead\n",
      "it\n",
      "defect type is\n",
      "line\n",
      "resulting\n",
      "like half\n",
      "results\n",
      "results in defects\n",
      "strip needs to\n",
      "will\n",
      "described in\n",
      "the contamination of\n",
      "will affect\n",
      "each\n",
      "type is described\n",
      "steel strip surface\n",
      "pits\n",
      "half a\n",
      "just\n",
      "may lead\n",
      "is described in\n",
      "according\n",
      "in detail\n",
      "contamination of mechanical\n",
      "affect the\n"
     ]
    }
   ],
   "source": [
    "display_concept(current_pipeline.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Term Extraction and Synonym Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 11:54:54,452] [WARNING] [pos_term_extraction] [__init__] [No preprocessing function provided for spans. Using the default one.]\n",
      "[2024-06-14 11:54:54,454] [WARNING] [pos_term_extraction] [_check_parameters] [POS term extraction token sequence attribute not set by the user.\n",
      "               By default the system will use the entire content of the document.]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[81], line 17\u001b[0m\n",
      "\u001b[1;32m     13\u001b[0m current_pipeline \u001b[38;5;241m=\u001b[39m postag_pipelines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;32m     14\u001b[0m current_pipeline\u001b[38;5;241m.\u001b[39mrun()\n",
      "\u001b[0;32m---> 17\u001b[0m \u001b[43mget_concept_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_concepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomparator_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomparator_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[50], line 47\u001b[0m, in \u001b[0;36mget_concept_ratio\u001b[0;34m(pipeline, expected_concepts, comparator, comparator_args)\u001b[0m\n",
      "\u001b[1;32m     43\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m \n",
      "\u001b[1;32m     46\u001b[0m precision \u001b[38;5;241m=\u001b[39m expected_concept_occ\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(expected_concepts)\n",
      "\u001b[0;32m---> 47\u001b[0m recall \u001b[38;5;241m=\u001b[39m \u001b[43mexpected_concept_occ\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfound_concepts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     48\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(precision \u001b[38;5;241m*\u001b[39m recall)\u001b[38;5;241m/\u001b[39m(precision\u001b[38;5;241m+\u001b[39mrecall)\n",
      "\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (precision, recall, f1)\n",
      "\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "postag_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            TFIDFTermExtraction(\n",
    "                max_term_token_length=3,\n",
    "                candidate_term_threshold=.2\n",
    "            ),\n",
    "            SynonymConceptExtraction()\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = postag_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Term Extraction and Agglomerative clustering Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-14 12:35:13,587] [WARNING] [tfidf_term_extraction] [_check_parameters] [Selected token sequence document attribute not set by the user.\n",
      "                By default the system will use the entire content of the document.]\n",
      "/home/oumar/Bureau/ontology-learning/env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1, 0.5, 0.16666666666666669)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_pipelines.append(\n",
    "    Pipeline(\n",
    "        spacy_model=nlp,\n",
    "        pipeline_components=[\n",
    "            TFIDFTermExtraction(\n",
    "                max_term_token_length=3,\n",
    "                candidate_term_threshold=.2\n",
    "            ),\n",
    "            AgglomerativeClusteringConceptExtraction(\n",
    "                distance_threshold=.3\n",
    "            )\n",
    "        ],\n",
    "        corpus=list(nlp.pipe(corpus)),\n",
    "    )\n",
    ")\n",
    "current_pipeline = postag_pipelines[-1]\n",
    "current_pipeline.run()\n",
    "\n",
    "\n",
    "get_concept_ratio(current_pipeline, expected_concepts, comparator_args=comparator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
